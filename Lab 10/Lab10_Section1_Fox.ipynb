{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Recommender System\n",
    "\n",
    "In this assignment, we will study how to do user-based collaborative filtering and item-based collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "In this assignment, we will use MovieLens-100K dataset. It includes about 100,000 ratings from 1000 users on 1700 movies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1664)\n",
      "(943, 1664)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# 1. load data\n",
    "user_ratings_train = pd.read_csv('./ml-100k/u1.base',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "user_ratings_test = pd.read_csv('./ml-100k/u1.test',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "movie_info =  pd.read_csv('./ml-100k/u.item', \n",
    "                          sep='|', names=['movie_id','title'], usecols=[0,1],\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "user_ratings_train = pd.merge(movie_info, user_ratings_train)\n",
    "user_ratings_test = pd.merge(movie_info, user_ratings_test)\n",
    "\n",
    "# 2. get the rating matrix. Each row is a user, and each column is a movie.\n",
    "user_ratings_train = user_ratings_train.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "user_ratings_test = user_ratings_test.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_ratings_train = user_ratings_train.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "user_ratings_test = user_ratings_test.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "print(user_ratings_train.shape)\n",
    "print(user_ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. User-based CF\n",
    "\n",
    "* Use pearson correlation to get the similarity between different users.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8316716024705649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "#replace Nans with row avg\n",
    "user_ratings_train['avg'] = user_ratings_train.mean(axis=1)\n",
    "user_ratings_train_noNan = user_ratings_train.T.fillna(user_ratings_train['avg'], axis=0).T\n",
    "\n",
    "pearson_sim_train = 1-pairwise_distances(user_ratings_train_noNan, metric=\"correlation\")\n",
    "\n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(pearson_sim_train)\n",
    "\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "neighbors_ind += 1 # +1 fixes off by one error since ids start at 1 instead of 0\n",
    "\n",
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "for user_id, row in user_ratings_test.iterrows():\n",
    "    for movie, rating in row.iteritems():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(0,10):\n",
    "                ngbh_id = neighbors_ind[user_id-1][x]\n",
    "                nghb_rating = user_ratings_train.loc[ngbh_id,movie]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = neighbors_distance[user_id-1][x]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating-user_ratings_train.loc[ngbh_id, 'avg'])\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predicted_rating += user_ratings_train.loc[user_id, 'avg']\n",
    "                predictions.append(predicted_rating)\n",
    "                actual.append(rating)\n",
    "\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print('MAE: ' + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Item-based CF\n",
    "* Use cosine similarity to get the similarity between different items.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.037206948070013\n"
     ]
    }
   ],
   "source": [
    "item_ratings_train = user_ratings_train.T\n",
    "item_ratings_test = user_ratings_test.T\n",
    "\n",
    "#replace Nans with row avg\n",
    "item_ratings_train['avg'] = item_ratings_train.mean(axis=1)\n",
    "item_ratings_train_noNan = item_ratings_train.T.fillna(item_ratings_train['avg'], axis=0).T\n",
    "\n",
    "#remove rows with no data\n",
    "dropped_rows = item_ratings_train_noNan[item_ratings_train_noNan.isna().any(axis=1)]\n",
    "item_ratings_train_noNan = item_ratings_train_noNan.drop(dropped_rows.index)\n",
    "item_ratings_test = item_ratings_test.drop(dropped_rows.index)\n",
    "\n",
    "pearson_sim_train = 1-pairwise_distances(item_ratings_train_noNan, metric=\"cosine\")\n",
    "\n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(pearson_sim_train)\n",
    "\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "neighbors_ind += 1 # +1 fixes off by one error since ids start at 1 instead of 0\n",
    "\n",
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "for movie_id, row in item_ratings_test.iterrows():\n",
    "    item_id = item_ratings_test.index.get_loc(movie_id)\n",
    "    for user, rating in row.iteritems():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(0,10):\n",
    "                ngbh_id = neighbors_ind[item_id][x]\n",
    "                nghb_rating = item_ratings_train.iloc[ngbh_id].loc[user]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = neighbors_distance[item_id][x]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating)\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predictions.append(predicted_rating)\n",
    "                actual.append(rating)\n",
    "\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print('MAE: ' + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
