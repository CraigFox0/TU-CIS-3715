{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will learn the Linear Regression model. \n",
    "\n",
    "First, please study the given example, which uses linear regression for the house price prediction task. In this example, you will learn how to preprocess data, how to train the model, and how to evaluate the model. \n",
    "\n",
    "Based on the given example and Lab Assignment 3, your task is to use the linear regression model to predict the medical cost for the dataset given in Lab Assignment 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example: Linear Regression for House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the house price dataset. It gives the attributes and price of each house. The task is to build a linear regression model to make prediction for the price of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preprocess the raw data\n",
    "\n",
    "When given a new dataset, we need to deal with the missing values and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "median_house_value    0\n",
      "ocean_proximity       0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null int64\n",
      "total_rooms           20640 non-null int64\n",
      "total_bedrooms        20640 non-null float64\n",
      "population            20640 non-null int64\n",
      "households            20640 non-null int64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null int64\n",
      "ocean_proximity       20640 non-null int64\n",
      "dtypes: float64(4), int64(6)\n",
      "memory usage: 1.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "# 0. fill in missing values\n",
    "mean_val = df['total_bedrooms'].mean()\n",
    "df['total_bedrooms'] = df['total_bedrooms'].fillna(mean_val)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 1. convert categorical features to numerical values\n",
    "labelencoder = LabelEncoder()\n",
    "df['ocean_proximity'] = labelencoder.fit_transform(df['ocean_proximity'])\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the preprocessed dataset into training set and testing set\n",
    "\n",
    "For the supervised learning, we need to split the dataset into the training set and test set. The training set is used to learn model parameters and the testing set is used to evaluate the learned model. \n",
    "\n",
    "Note that the testing set is NOT allowed to be used in the training phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 9)\n",
      "(4128, 9)\n"
     ]
    }
   ],
   "source": [
    "# 2. split samples\n",
    "house_fea = df.drop('median_house_value', axis=1).values\n",
    "house_price = df['median_house_value'].values\n",
    "house_price = house_price / np.max(house_price)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(house_fea,\n",
    "                                                 house_price,\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "# normalize features\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train the linear regression model \n",
    "\n",
    "$\\min_{w}\\frac{1}{n}\\|y-X\\mathbf{w}\\|_2^2$\n",
    "\n",
    "\n",
    "\n",
    "Here, we use the training set to learn the model parameter $\\mathbf{w}=(w_0, w_1, w_2, \\cdots, w_d)$. \n",
    "\n",
    "Then, we compute MAE, MSE, and RMSE to see how well the learned model fit the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias is 0.41438855869860675\n",
      "coefficients  is [-0.17170955 -0.18189176  0.02984855 -0.0353864   0.09753502 -0.08776816\n",
      "  0.03520256  0.15428789 -0.00090304]\n",
      "prediction for training set:\n",
      "MAE is: 0.10125365457873205\n",
      "MSE is: 0.0192437559440504\n",
      "RMSE is: 0.13872186541439818\n"
     ]
    }
   ],
   "source": [
    "#3. train the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \"+str(lr.intercept_))\n",
    "print(\"coefficients  is \"+str(lr.coef_))\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "mae = mean_absolute_error(y_train_pred,y_train)\n",
    "mse = mean_squared_error(y_train_pred,y_train)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate the linear regression model\n",
    "\n",
    "After obtaining the model parameter $\\mathbf{w}=(w_0, w_1, w_2, \\cdots, w_d)$, the linear regression model is determined. Then, we need to evaluate this model to see how well this model generaizes on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for testing set:\n",
      "MAE is: 0.1036935483109797\n",
      "MSE is: 0.02022001958450324\n",
      "RMSE is: 0.14219711524677017\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAF11JREFUeJzt3X2UVfW93/H3VwVBQbkKbdRRZ+4KKRrEEUd6E/GBi/H6QKAxWkF8ahJGTahZzUNL7I21JKY22kQlelNsoibFZ41ipPE2uZqI0SiUkauoCcpEZpGsKCYmBLmAfvvHObPvMA4zA8yeA8z7tdYszt7nd37nu/cM53N+e+/zO5GZSJIEsEetC5Ak7TwMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBX2qnUB22rkyJFZX19f6zIkaZeydOnSNzJzVE/tdrlQqK+vZ8mSJbUuQ5J2KRHx69608/CRJKlgKEiSCoaCJKmwy51TkLRz2rRpE21tbWzYsKHWpQxoQ4YMoa6ujkGDBm3X4w0FSX2ira2N4cOHU19fT0TUupwBKTNZu3YtbW1tNDQ0bFcfpR0+iojvRsTvIuL5rdwfEXFjRKyMiOURMb6sWiSVb8OGDRx44IEGQg1FBAceeOAOjdbKPKdwG3BaN/efDoyu/jQDf1diLZL6gYFQezv6OygtFDLzZ8Cb3TSZBnwvK54GRkTEQWXVI0nqWS3PKRwCrO6w3FZd95valCOpL9XPeaRP+2u95sw+7a+vPf7441x33XX88Ic/3GJ9S0sLa9as4YwzztjmPr/2ta9xxRVXANDa2sqUKVN4/vkuj8j3mVqGQldjnOyyYUQzlUNMHHbYYWXWpAGgr1+s2u3sL1qCzZs3s9de/fuy19LSwpIlS7oMhZ7q6RgK/aWWn1NoAw7tsFwHrOmqYWbOz8ymzGwaNarHqTskDUBf+cpXGDNmDB/5yEeYMWMG1113HQAnn3wyV1xxBSeddBI33HADv/71r5k8eTLjxo1j8uTJvPbaawBcfPHF3HfffUV/w4YNAyojgJNPPpmzzz6bMWPGMHPmTDIr719/9KMfMWbMGCZOnMgDDzzwnpo2btzIlVdeyd13301jYyN33303V111Fc3NzZx66qlceOGF3HbbbcyePbt4zJQpU3j88ceZM2cOb7/9No2NjcycOROAd955h1mzZvHBD36QU089lbfffrvP92MtQ2EhcGH1KqS/At7KTA8dSdpmS5Ys4f7772fZsmU88MAD75kf7Q9/+AM//elP+fznP8/s2bO58MILWb58OTNnzuTyyy/vsf9ly5Zx/fXXs2LFCl599VWefPJJNmzYwKxZs3j44Yd54okn+O1vf/uexw0ePJi5c+dy7rnn0tLSwrnnngvA0qVLeeihh7jjjju2+pzXXHMNQ4cOpaWlhQULFgDwq1/9is985jO88MILjBgxgvvvv39bdlOvlHlJ6p3AU8C/ioi2iPhkRFwaEZdWmywCXgVWArcAny6rFkm7t8WLFzNt2jSGDh3K8OHD+ehHP7rF/e0vxgBPPfUU5513HgAXXHABixcv7rH/CRMmUFdXxx577EFjYyOtra289NJLNDQ0MHr0aCKC888/v9f1Tp06laFDh/a6fbuGhgYaGxsBOPbYY2ltbd3mPnpS2sG1zJzRw/0JfKas55c0cLQfztmafffdd6v3tV/Cuddee/Huu+8W/W3cuLFos/feexe399xzTzZv3rzFY7dVx3o6Pi/Q7WcMOtexux0+kqQ+MXHiRB5++GE2bNjAunXreOSRrV9M8OEPf5i77roLgAULFjBx4kSgMi3/0qVLAXjooYfYtGlTt885ZswYVq1axSuvvALAnXfe2WW74cOH86c//Wmr/dTX19PS0sK7777L6tWreeaZZ4r7Bg0a1GMdfc1pLiSVoj+vxjruuOOYOnUqRx99NIcffjhNTU3sv//+Xba98cYb+cQnPsG1117LqFGjuPXWWwGYNWsW06ZNY8KECUyePLnb0QVU5hiaP38+Z555JiNHjmTixIldXi46adIkrrnmGhobG/nSl770nvuPP/54GhoaOOqooxg7dizjx//z5A7Nzc2MGzeO8ePHc/XVV2/LLtlu0dOwa2fT1NSUfsmOdoSXpJbjxRdf5IgjjqjZ869bt45hw4axfv16TjzxRObPn7/FC+xA0tXvIiKWZmZTT491pCBpt9Dc3MyKFSvYsGEDF1100YANhB1lKEjaLXR3ead6zxPNkqSCoSBJKhgKkqSCoSBJKniiWVI5rur6cwLb399bfdtfD4YNG8a6detYs2YNl19++RaT5XV2/fXX09zczD777APAGWecwR133MGIESP6q9w+40hB0oDxzjvvbPNjDj744G4DASqhsH79+mJ50aJFu2QggKEgaTfR2trKmDFjuOiiixg3bhxnn30269evp76+nrlz5zJx4kTuvfdeXnnlFU477TSOPfZYTjjhBF566SUAVq1axYc+9CGOO+44vvzlL2/R79ixY4FKqHzhC1/gqKOOYty4ccybN48bb7yRNWvWMGnSJCZNmgRUpq544403APjGN77B2LFjGTt2LNdff33R5xFHHFH6NNjbw1CQtNt4+eWXaW5uZvny5ey3337cfPPNQGVKisWLFzN9+nSam5uZN28eS5cu5brrruPTn65M0PzZz36Wyy67jGeffZb3ve99XfY/f/58Vq1axbJly7aYevvggw/mscce47HHHtui/dKlS7n11lv5xS9+wdNPP80tt9zCsmXLgP6ZBnt7GAqSdhuHHnooxx9/PADnn39+MS12+9TZ69at4+c//znnnHMOjY2NXHLJJfzmN5WvcXnyySeZMaMyufMFF1zQZf8//vGPufTSS4tvSzvggAO6rWfx4sV87GMfY99992XYsGGcddZZPPHEE0D/TIO9PTzRLGm30Xkq6/bl9snt3n33XUaMGEFLS0uvHt9ZZm7TdNndzS3XH9Ngbw9HCpJ2G6+99hpPPfUUUJnKun1a7Hb77bcfDQ0N3HvvvUDlRfu5554DKrOVdpxSuyunnnoq3/72t4vvU3jzzTeBrU+PfeKJJ/Lggw+yfv16/vznP/ODH/yAE044oQ+2tDyOFCSVo58vIQU44ogjuP3227nkkksYPXo0l112GfPmzduizYIFC7jsssv46le/yqZNm5g+fTpHH300N9xwA+eddx433HADH//4x7vs/1Of+hS//OUvGTduHIMGDWLWrFnMnj2b5uZmTj/9dA466KAtziuMHz+eiy++mAkTJhSPP+aYY3aaQ0VdcepsDThOnV2OWk+d3draypQpU7r8ToOBZkemzvbwkSSpYChI2i3U19c7SugDhoKkPrOrHY7eHe3o78BQkNQnhgwZwtq1aw2GGspM1q5dy5AhQ7a7D68+ktQn6urqaGtr4/XXX691KQPakCFDqKur2+7HGwqS+sSgQYNoaGiodRnaQR4+kiQVDAVJUsFQkCQVDAVJUsFQkCQVDAVJUsFQkCQVDAVJUqHUUIiI0yLi5YhYGRFzurj/sIh4LCKWRcTyiDijzHokSd0rLRQiYk/gJuB04EhgRkQc2anZ3wL3ZOYxwHTg5rLqkST1rMyRwgRgZWa+mpkbgbuAaZ3aJLBf9fb+wJoS65Ek9aDMuY8OAVZ3WG4D/nWnNlcBfx8R/x7YFzilxHokST0oc6QQXazrPKfuDOC2zKwDzgC+HxHvqSkimiNiSUQscQZGSSpPmaHQBhzaYbmO9x4e+iRwD0BmPgUMAUZ27igz52dmU2Y2jRo1qqRyJUllhsKzwOiIaIiIwVROJC/s1OY1YDJARBxBJRQcCkhSjZQWCpm5GZgNPAq8SOUqoxciYm5ETK02+zwwKyKeA+4ELk6/tkmSaqbUL9nJzEXAok7rruxwewVwfJk1SJJ6z080S5IKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqWAoSJIKpYZCRJwWES9HxMqImLOVNv82IlZExAsRcUeZ9UiSurdXWR1HxJ7ATcBHgDbg2YhYmJkrOrQZDXwJOD4zfx8R/6KseiRJPStzpDABWJmZr2bmRuAuYFqnNrOAmzLz9wCZ+bsS65Ek9aDMUDgEWN1hua26rqMPAB+IiCcj4umIOK3EeiRJPSjt8BEQXazLLp5/NHAyUAc8ERFjM/MPW3QU0Qw0Axx22GF9X6kkCSh3pNAGHNphuQ5Y00WbhzJzU2auAl6mEhJbyMz5mdmUmU2jRo0qrWBJGujKDIVngdER0RARg4HpwMJObR4EJgFExEgqh5NeLbEmSVI3SguFzNwMzAYeBV4E7snMFyJibkRMrTZ7FFgbESuAx4AvZubasmqSJHWvzHMKZOYiYFGndVd2uJ3A56o/kqQa26aRQkTsW1YhkqTa61UoRMSHq4d4XqwuHx0RN5damSSp3/V2pPBN4G+AtQCZ+RxwYllFSZJqo9eHjzJzdadV7/RxLZKkGuvtiebVEfFhIKuXl15O9VCSJO1q6uc8UlrfrUPOK61vrnqrvL6rehsKlwI3UJmmog34e+AzZRUlaRd11f4l9l3+C6J6GQqZ+QYws+RaJEk11turj26PiBEdlv8iIr5bXlmSpFro7YnmcR0nqatOdX1MOSVJkmqlt+cU9oiIv2j/3oOIOGAbHisNDB5P126gty/s/wP4eUTcV10+B7i6nJIkSbXS2xPN34uIJcBfU/mehLM6fq2mJGn30G0oRMR+mfnH6uGi3wJ3dLjvgMx8s+wCJUn9p6eRwh3AFGApW35rWlSX/7KkuiRJNdBtKGTmlIgI4KTMfK2fapIk1UiPl6RWv/PgB/1QiySpxnr7OYWnI+K4UiuRJNVcby9JnQRcGhGtwJ+pnlPIzHFlFSZJ6n+9DYXTS61CkrRT6OmS1CFUZkh9P/CPwHcyc3N/FCZJ6n89nVO4HWiiEginU/lksyRpN9XT4aMjM/MogIj4DvBM+SVJkmqlp5HCpvYbHjaSpN1fTyOFoyPij9XbAQytLrdffbRfqdVJkvpVT59o3rO/CpEk1V5vP7wmSRoADAVJUsFQkCQV/EpNaQCqn/NIKf22DimlW/UjRwqSpIKhIEkqGAqSpEKpoRARp0XEyxGxMiLmdNPu7IjIiGgqsx5JUvdKC4WI2BO4icpEekcCMyLiyC7aDQcuB35RVi2SpN4pc6QwAViZma9m5kbgLmBaF+2+Anwd2FBiLZKkXigzFA4BVndYbquuK0TEMcChmfnDEuuQJPVSmaEQXazL4s6IPYBvAp/vsaOI5ohYEhFLXn/99T4sUZLUUZmh0AYc2mG5DljTYXk4MBZ4vPrdz38FLOzqZHNmzs/MpsxsGjVqVIklS9LAVmYoPAuMjoiGiBgMTAcWtt+ZmW9l5sjMrM/MeuBpYGpmLimxJklSN0oLheqX8swGHgVeBO7JzBciYm5ETC3reSVJ26/UuY8ycxGwqNO6K7fS9uQya5Ek9cxPNEuSCoaCJKlgKEiSCoaCJKlgKEiSCoaCJKlgKEiSCoaCJKlgKEiSCqV+olkDzFX7l9TvW+X0K+k9HClIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqGgiSpYChIkgqlhkJEnBYRL0fEyoiY08X9n4uIFRGxPCJ+EhGHl1mPJKl7pYVCROwJ3AScDhwJzIiIIzs1WwY0ZeY44D7g62XVI0nqWZkjhQnAysx8NTM3AncB0zo2yMzHMnN9dfFpoK7EeiRJPSgzFA4BVndYbquu25pPAv+nqzsiojkilkTEktdff70PS5QkdVRmKEQX67LLhhHnA03AtV3dn5nzM7MpM5tGjRrVhyVKkjraq8S+24BDOyzXAWs6N4qIU4D/DJyUmf9UYj2SpB6UOVJ4FhgdEQ0RMRiYDizs2CAijgH+JzA1M39XYi2SpF4oLRQyczMwG3gUeBG4JzNfiIi5ETG12uxaYBhwb0S0RMTCrXQnSeoHZR4+IjMXAYs6rbuyw+1Tynx+SdK28RPNkqSCoSBJKhgKkqSCoSBJKpR6onlAuWr/Evt+q7y+JakDRwqSpIKhIEkqGAqSpIKhIEkqGAqSpIKhIEkqGAqSpIKhIEkqGAqSpIKhIEkqGAqSpMKAmvuofs4jpfXdOqS0riWp3wyoUJDBKKl7Hj6SJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSodRQiIjTIuLliFgZEXO6uH/viLi7ev8vIqK+zHokSd0rLRQiYk/gJuB04EhgRkQc2anZJ4HfZ+b7gW8C/72seiRJPStzpDABWJmZr2bmRuAuYFqnNtOA26u37wMmR0SUWJMkqRtlhsIhwOoOy23VdV22yczNwFvAgSXWJEnqRplfx9nVO/7cjjZERDPQXF1cFxEv72BtfS5gJPBGKZ3/111j8FTaPhjo2w/uA3AfwI7ug8N706jMUGgDDu2wXAes2UqbtojYC9gfeLNzR5k5H5hfUp19IiKWZGZTreuopYG+Dwb69oP7AHb9fVDm4aNngdER0RARg4HpwMJObRYCF1Vvnw38Q2a+Z6QgSeofpY0UMnNzRMwGHgX2BL6bmS9ExFxgSWYuBL4DfD8iVlIZIUwvqx5JUs/KPHxEZi4CFnVad2WH2xuAc8qsoR/t1Ie3+slA3wcDffvBfQC7+D4Ij9ZIkto5zYUkqTDgQyEi1nVavjgivtVPzz27OsVHRsTI/njOrdRRy32woDoVyvMR8d2IGNQfz9tFHbXcB9+JiOciYnlE3BcRw/rjeTvVULPt7/Cc8zrX0c/PX8u/gdsiYlVEtFR/Gvvjebsy4EOhxp4ETgF+XetCamgBMAY4ChgKfKq25dTEf8jMozNzHPAaMLvWBfW3iGgCRtS6jhr7YmY2Vn9aalWEodCNiDg8In5SfQf3k4g4rLr+tog4u0O7ddV/D4qIn1WT/vmIOKG6/tSIeCoi/l9E3Nv+TjAzl2Vmaw02rdf6YR8syirgGSqfZ9mp9MM++GP1/qASjDvVib6ytz8q86RdC/zH/t+63il7H+xMDAUY2mHI1gLM7XDft4DvVd/BLQBu7KGv84BHM7MROBpoqR4W+lvglMwcDywBPtfnW7Fjar4PqoeNLgB+1CdbtO1qug8i4lbgt1RGTfP6aqO2QS23fzawMDN/04fbsz1q/f/g6mrofDMi9u6rjdpWpV6Suot4u/qLAyrHEYH2TyN+CDirevv7wNd76OtZoP24+IOZ2RIRJ1GZJfbJyhtBBgNP9V35fWJn2Ac3Az/LzCd2ZEN2QE33QWb+u+o75nnAucCtO7xF26Ym2x8RB1O5LP3kPtqOHVHLv4EvUXlTMJjKJa3/iS1Dqd8YCtumfVi/meooqzrkHwyQmT+LiBOBM6l8KO9a4PfA/83MGTWotwx9vg8i4r8Ao4BLSq69r5Tyd5CZ70TE3cAX6f9Q2BZ9tv0RcSbwfmBl9YVyn4hYWZ1Of2fWp38DHUZJ/1QdNX6h5Pq3ysNH3fs5//wp65nA4urtVuDY6u1pwCCoHHcEfpeZt1D5tPZ44Gng+Ih4f7XNPhHxgX6pvm+Uug8i4lPA3wAzMvPd0rdm+5S2D6KifV0AHwVeKn2Ltk1p25+Zj2Tm+zKzPjPrgfU7aSCU/f/goOq/Afwb4PmSt2frMnNA/wDrOi1fDHyrerse+AdgOfAT4LDq+n9J5Rf8DPDf2vugMo/T88Ay4Amgobr+r6kMJ5dXf6ZW119OZVLAzVQmC/xfA3AfbAZeAVqqP1cOpH1A5Y3Zk8A/Vh+zANhvoGx/T3UMlH1Q7bv9b+B/A8NqtR/8RLMkqeDhI0lSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBX+P3YXqPlUl7rXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4. evaluate the model\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "\n",
    "labels = ['House1', 'House2', 'House3', 'House4', 'House5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, y_test[0:5], width, label='ground truth')\n",
    "rects2 = ax.bar(x + width/2, y_test_pred[0:5], width, label='prediction')\n",
    "\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task: Linear Regression for Medical Cost Prediction\n",
    "\n",
    "Following the given example, build a linear regression model for [the insurance dataset](./insurance.csv) to predict the medical cost.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess the raw data\n",
    "\n",
    "Based on your Lab Assignment 3, deal with the missing values and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature   missing values\n",
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "insurance_df = pd.read_csv('insurance.csv')\n",
    "\n",
    "print('feature   missing values')\n",
    "print(insurance_df.isnull().sum())\n",
    "print('No missing values')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "insurance_df['sex'] = labelencoder.fit_transform(insurance_df['sex'])\n",
    "insurance_df['smoker'] = labelencoder.fit_transform(insurance_df['smoker'])\n",
    "insurance_df['region'] = labelencoder.fit_transform(insurance_df['region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the preprocessed dataset into training set and testing set\n",
    "\n",
    "Use 80% of samples as the training set and 20% of samples as the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_fea = insurance_df.drop('charges', axis=1).values\n",
    "insurance_charges = insurance_df['charges'].values\n",
    "insurance_charges = insurance_charges / np.max(insurance_charges)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(insurance_fea,\n",
    "                                                 insurance_charges,\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=42)\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train the linear regression model \n",
    "\n",
    "Use the Linear regression model to do prediction\n",
    "\n",
    "$\\min_{w}\\frac{1}{n}\\|y-X\\mathbf{w}\\|_2^2$\n",
    "\n",
    "Please output the learned model parameter $\\mathbf{w}$ and see how the learned model fit the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias is 0.20928336460705027\n",
      "coefficients are[ 5.67051024e-02 -1.47293258e-04  3.18064131e-02  8.10191467e-03\n",
      "  1.49867951e-01 -4.74182139e-03]\n",
      "Prediction for Training Set\n",
      "MAE is: 0.0659986479709151\n",
      "MSE is: 0.00916737434945697\n",
      "RMSE is: 0.09574640645714579\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \"+str(lr.intercept_))\n",
    "print(\"coefficients are\"+str(lr.coef_))\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "mae = mean_absolute_error(y_train_pred,y_train)\n",
    "mse = mean_squared_error(y_train_pred,y_train)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Prediction for Training Set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate the linear regression model\n",
    "\n",
    "\n",
    "Evaluate the learned model to see how well this model generaizes on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Testing Set\n",
      "MAE is: 0.06564969107169769\n",
      "MSE is: 0.008270951713078177\n",
      "RMSE is: 0.09094477287386107\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Prediction for Testing Set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "\n",
    "labels = ['Charge 1', 'Charge 2', 'Charge 3', 'Charge 4', 'Charge 5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, y_test[0:5], width, label='ground truth')\n",
    "rects2 = ax.bar(x + width/2, y_test_pred[0:5], width, label='prediction')\n",
    "\n",
    "ax.set_ylabel('Charge')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Use the ridge regression model to do prediction\n",
    "\n",
    "$\\min_{w}\\frac{1}{n}\\|y-Xw\\|_2^2 + \\lambda \\|w\\|_2^2$\n",
    "\n",
    "* 1.5.1 Compare its performance on the testing set with that of the standard linear regression model $\\min_{w}\\frac{1}{n}\\|y-Xw\\|_2^2$\n",
    "\n",
    "* 1.5.2 Use different $\\lambda$ to see how it affects the performance of the ridge regression  model on the testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression with lambda value of 1\n",
      "bias is 0.20928336460705027\n",
      "coefficients are [ 5.66477072e-02 -1.36912304e-04  3.17814658e-02  8.09963575e-03\n",
      "  1.49724329e-01 -4.73350751e-03]\n",
      "Prediction for Testing Set\n",
      "MAE is: 0.06567262940074661\n",
      "MSE is: 0.008272576669548302\n",
      "RMSE is: 0.09095370618918341\n",
      "\n",
      "Ridge Regression with lambda value of .5\n",
      "bias is 0.20928336460705027\n",
      "coefficients are [ 5.66763901e-02 -1.42097922e-04  3.17939348e-02  8.10077598e-03\n",
      "  1.49796105e-01 -4.73766172e-03]\n",
      "Prediction for Testing Set\n",
      "MAE is: 0.06566116640105905\n",
      "MSE is: 0.008271758135158371\n",
      "RMSE is: 0.0909492063470505\n",
      "\n",
      "Ridge Regression with lambda value of 2\n",
      "bias is 0.20928336460705027\n",
      "coefficients are [ 5.65904294e-02 -1.26570140e-04  3.17565563e-02  8.09735070e-03\n",
      "  1.49580983e-01 -4.72521546e-03]\n",
      "Prediction for Testing Set\n",
      "MAE is: 0.06569551848974604\n",
      "MSE is: 0.00827424993038479\n",
      "RMSE is: 0.09096290414440818\n"
     ]
    }
   ],
   "source": [
    "rr = Ridge(alpha = 1)\n",
    "print('Ridge Regression with lambda value of 1')\n",
    "\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \"+str(rr.intercept_))\n",
    "print(\"coefficients are \"+str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Prediction for Testing Set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "rr = Ridge(alpha = .5)\n",
    "print('\\nRidge Regression with lambda value of .5')\n",
    "\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \"+str(rr.intercept_))\n",
    "print(\"coefficients are \"+str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Prediction for Testing Set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "rr = Ridge(alpha = 2)\n",
    "print('\\nRidge Regression with lambda value of 2')\n",
    "\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \"+str(rr.intercept_))\n",
    "print(\"coefficients are \"+str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Prediction for Testing Set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using ridge regressions with lambdas of 1, 2, and 0.5, all performed worse than the linear regression although not by a significant amount. The ridge regression with lambda of 0.5 performed the best out of the ridge regressions. However all three measures of performance were still worse than the linear regression. The MAE was more than .000011 higher, the MSE was more than 0.0000008 higher, and the RMSE is more than 0.000004 higher. As the lambda values increased, the performance declined although the difference was low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
