{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rock Climbing Analysis and Recommendation System\n",
    "\n",
    "This notebook collects rock climbing route data from Mountain Project. It performs analysis on this data and creates a recommendation system to predict how much a user would like a route. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mountain Project contains hundreds of thousands of climbs. Set the limits below for how many climbs to collect for the analysis section and for the recommendation algorithm section. The analysis data is mainly limited by the length of time to crawl the web pages. The recommendation algorithm is mainly limited by the memory and runtime speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_climbs_data_to_collect = 25000\n",
    "number_of_climbs_for_recommendation_system = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scans through the sitemap files of Mountain Project to collect a list of route ids. You must have the sitemap files already downloaded and stored in the same location as this notebook.\n",
    "\n",
    "Input: Sitemap files\n",
    "\n",
    "Output: List of valid climb ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_climbs = []\n",
    "#valid_users = []\n",
    "\n",
    "sitemap_ids = list(range(0,100))\n",
    "\n",
    "for sitemap_id in sitemap_ids:\n",
    "    file = 'Site Maps/sitemap' + str(sitemap_id) + '.xml'\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    for child in root:\n",
    "        text = re.split('/',child[0].text)\n",
    "        if len(text) > 3:\n",
    "            if text[3] == 'route':\n",
    "                valid_climbs.append(text[4])\n",
    "            # Uncomment this to collect user ids as well\n",
    "            #elif text[3] == 'user':\n",
    "                #valid_users.append(text[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This collects the basic data about routes from the Mountain Project website\n",
    "\n",
    "Input: List of valid climb ids\n",
    "\n",
    "Output: CSV of climb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "\n",
    "df = pd.DataFrame(columns=['Id', 'Name', 'Difficulty', 'Star Rating', 'Number of Ratings', 'Type', 'Page Views', 'Description'])\n",
    "\n",
    "#double check no more processing is needed\n",
    "\n",
    "if number_of_climbs_data_to_collect < len(valid_climbs):\n",
    "    valid_climbs = valid_climbs[:number_of_climbs_data_to_collect]\n",
    "\n",
    "for climb_id in valid_climbs:\n",
    "    URL = 'https://www.mountainproject.com/route/' + str(climb_id) + '/'\n",
    "    page = s.get(URL)\n",
    "    \n",
    "    main = BeautifulSoup(page.content, 'html.parser').find('body', id='body-climb').find('div', class_='main-content-container').find('div', class_='container-fluid').find('div', id='route-page').find('div', class_='row pt-main-content')\n",
    "\n",
    "    top = main.find('div', class_='col-md-9 float-md-right mb-1')\n",
    "    climb_name = top.find('h1').text.strip()\n",
    "    difficulty_rating = top.find('h2', class_='inline-block mr-2')\n",
    "    if (difficulty_rating.find('span', class_='rateYDS') is not None):\n",
    "        YDS_difficulty_rating = difficulty_rating.find('span', class_='rateYDS').text[:-4]\n",
    "        star_rating = re.split(' |\\n',top.find('span', id='route-star-avg').find('span').find('a', class_='show-tooltip').find('span', id=('starsWithAvgText-'+str(climb_id))).text.strip())\n",
    "        star_rating_numeric = star_rating[1]\n",
    "        star_rating_people = star_rating[3]\n",
    "\n",
    "        body = main.find('div', class_='col-md-9 main-content float-md-right').find('div', class_='row')\n",
    "\n",
    "        info = body.find('div').find('div', class_='small mb-1').table.find_all('tr')\n",
    "        info_type = info[0].find_all('td')[1].text.strip()\n",
    "        info_page_views = re.split(' ',info[2].find_all('td')[1].text.strip())[0]\n",
    "\n",
    "        description = body.find('div', class_='col-xs-12')\n",
    "        description_text = description.find('div', class_='mt-2 max-height max-height-md-800 max-height-xs-600').find('div', class_='fr-view').text\n",
    "        \n",
    "        new_route = {'Id':climb_id, 'Name':climb_name, 'Difficulty':YDS_difficulty_rating, 'Star Rating':star_rating_numeric, 'Number of Ratings':star_rating_people, 'Type':info_type, 'Page Views':info_page_views, 'Description':description_text}\n",
    "        df = df.append(new_route, ignore_index=True)\n",
    "df.to_csv('route_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts the climb data into a more useable format\n",
    "\n",
    "Input: CSV of climb data\n",
    "\n",
    "Output: CSV of processed climb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data_processed = pd.read_csv('route_data.csv', index_col='Id').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "route_data_processed['Page Views']=route_data_processed['Page Views'].str.replace(',','')\n",
    "\n",
    "route_data_processed = route_data_processed.astype({'Name': 'str', 'Difficulty': 'str', 'Star Rating': 'float64', 'Number of Ratings': 'str','Type': 'str','Page Views': 'int32','Description': 'str'})\n",
    "\n",
    "#Converts Difficulty\n",
    "\n",
    "#Removes difficulties containing V\n",
    "route_data_processed = route_data_processed[route_data_processed['Difficulty'].str.contains('V') == False]\n",
    "#Changes + to c and - to b\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('\\+','c')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('\\-','b')\n",
    "#Changes /s to lower value\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('\\/.','')\n",
    "#Convets grade letters to integer system to make it easier for analysis\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('5\\.', '')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('3rd', '-2')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('4th', '-1')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('Easy 5th', '0')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('10a', '10')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('10b', '11')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('10c', '12')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('10d', '13')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('11a', '14')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('11b', '15')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('11c', '16')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('11d', '17')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('12a', '18')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('12b', '19')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('12c', '20')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('12d', '21')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('13a', '22')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('13b', '23')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('13c', '24')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('13d', '25')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('14a', '26')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('14b', '27')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('14c', '28')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('14d', '29')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('15a', '30')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('15b', '31')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('15c', '32')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('15d', '33')\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].str.replace('[a-d]', '')\n",
    "\n",
    "#Fixes Difficulty column to proper type\n",
    "route_data_processed['Difficulty'] = route_data_processed['Difficulty'].astype('int32')\n",
    "\n",
    "#Fixes Number of Ratings column to proper type\n",
    "route_data_processed['Number of Ratings'] = route_data_processed['Number of Ratings'].str.replace(',', '')\n",
    "route_data_processed['Number of Ratings'] = route_data_processed['Number of Ratings'].astype('int32')\n",
    "\n",
    "#Breaks up the type column\n",
    "type_data = route_data_processed['Type'].str.split(', ', expand=True)\n",
    "route_data_processed['Trad'] = False\n",
    "route_data_processed['Sport'] = False\n",
    "route_data_processed['Top Rope'] = False\n",
    "route_data_processed['Alpine'] = False\n",
    "route_data_processed['Aid'] = False\n",
    "route_data_processed['Boulder'] = False\n",
    "route_data_processed['Snow'] = False\n",
    "route_data_processed['Ice'] = False\n",
    "route_data_processed['Mixed'] = False\n",
    "route_data_processed['Length (m)'] = 0\n",
    "route_data_processed['Pitches'] = 1\n",
    "route_data_processed['Grade'] = 1\n",
    "\n",
    "for index, row in type_data.iterrows():\n",
    "    for item in row:\n",
    "        if pd.notnull(item):\n",
    "            if 'Trad' in item:\n",
    "                route_data_processed.loc[index,'Trad'] = True\n",
    "            elif 'Sport' in item:\n",
    "                route_data_processed.loc[index,'Sport'] = True\n",
    "            elif 'TR' in item:\n",
    "                route_data_processed.loc[index,'Top Rope'] = True\n",
    "            elif 'Alpine' in item:\n",
    "                route_data_processed.loc[index,'Alpine'] = True\n",
    "            elif 'Aid' in item:\n",
    "                route_data_processed.loc[index,'Aid'] = True\n",
    "            elif 'Boulder' in item:\n",
    "                route_data_processed.loc[index,'Boulder'] = True\n",
    "            elif 'Snow' in item:\n",
    "                route_data_processed.loc[index,'Snow'] = True\n",
    "            elif 'Ice' in item:\n",
    "                route_data_processed.loc[index,'Ice'] = True\n",
    "            elif 'Mixed' in item:\n",
    "                route_data_processed.loc[index,'Mixed'] = True\n",
    "            elif 'ft' in item:\n",
    "                route_data_processed.loc[index,'Length (m)'] = re.split(' ',item)[2][1:]\n",
    "            elif 'pitches' in item:\n",
    "                route_data_processed.loc[index,'Pitches'] = re.split(' ',item)[0]\n",
    "            elif 'Grade' in item:\n",
    "                grade = re.split(' ',item)[1]\n",
    "                if grade == 'I':\n",
    "                    route_data_processed.loc[index,'Grade'] = 1\n",
    "                elif grade == 'II':\n",
    "                    route_data_processed.loc[index,'Grade'] = 2\n",
    "                elif grade == 'III':\n",
    "                    route_data_processed.loc[index,'Grade'] = 3\n",
    "                elif grade == 'IV':\n",
    "                    route_data_processed.loc[index,'Grade'] = 4\n",
    "                elif grade == 'V':\n",
    "                    route_data_processed.loc[index,'Grade'] = 5\n",
    "                elif grade == 'VI':\n",
    "                    route_data_processed.loc[index,'Grade'] = 6\n",
    "                elif grade == 'VII':\n",
    "                    route_data_processed.loc[index,'Grade'] = 7\n",
    "\n",
    "route_data_processed['Length (m)'] = route_data_processed['Length (m)'].astype('int32')\n",
    "route_data_processed['Pitches'] = route_data_processed['Pitches'].astype('int32')\n",
    "route_data_processed['Grade'] = route_data_processed['Grade'].astype('int32')\n",
    "\n",
    "route_data_processed = route_data_processed.drop(['Type'], axis=1)\n",
    "\n",
    "route_data_processed.to_csv('route_data_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs an exploratory analysis of the climb data\n",
    "\n",
    "Input: CSV of processed climb data\n",
    "\n",
    "Output: Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data_processed = pd.read_csv('route_data_processed.csv', index_col='Id')\n",
    "\n",
    "print(route_data_processed.dtypes)\n",
    "print(route_data_processed.info())\n",
    "\n",
    "#Distribution Analysis\n",
    "route_data_processed['Star Rating'].hist(bins=8)\n",
    "plt.title('Star Rating Histogram')\n",
    "plt.xlabel(\"Star Ratings\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig('star_rating_histogram.png')\n",
    "plt.clf()\n",
    "route_data_processed['Number of Ratings'].hist(bins=20)\n",
    "plt.title('Number of Ratings Histogram')\n",
    "plt.xlabel(\"Number of Ratings\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig('number_of_ratings_histogram.png')\n",
    "plt.clf()\n",
    "route_data_processed['Page Views'].hist(bins=20)\n",
    "plt.title('Page Views Histogram')\n",
    "plt.xlabel(\"Page Views\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig('page_views_histogram.png')\n",
    "plt.clf()\n",
    "route_data_processed['Length (m)'].hist(bins=10)\n",
    "plt.title('Length (m) Histogram')\n",
    "plt.xlabel(\"Length (m)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig('length_histogram.png')\n",
    "plt.clf()\n",
    "route_data_processed['Difficulty'].value_counts().sort_index().plot.bar()\n",
    "plt.title('Difficulty Breakdown')\n",
    "plt.savefig('difficulty_breakdown.png')\n",
    "plt.clf()\n",
    "route_data_processed['Pitches'].value_counts().sort_index().plot.bar()\n",
    "plt.title('Pitches Breakdown')\n",
    "plt.savefig('pitches_breakdown.png')\n",
    "plt.clf()\n",
    "route_data_processed['Grade'].value_counts().sort_index().plot.bar()\n",
    "plt.title('Grade Breakdown')\n",
    "plt.savefig('grade_breakdown.png')\n",
    "plt.clf()\n",
    "route_data_processed['Trad'].value_counts().sort_index().plot.bar()\n",
    "plt.title('Trad Breakdown')\n",
    "plt.savefig('trad_breakdown.png')\n",
    "plt.clf()\n",
    "route_data_processed['Sport'].value_counts().sort_index().plot.bar()\n",
    "plt.title('Sport Breakdown')\n",
    "plt.savefig('sport_breakdown.png')\n",
    "plt.clf()\n",
    "route_data_processed['Top Rope'].value_counts().sort_index().plot.bar()\n",
    "plt.title('Top Rope Breakdown')\n",
    "plt.savefig('top_rope_breakdown.png')\n",
    "plt.clf()\n",
    "print(route_data_processed['Alpine'].value_counts())\n",
    "print(route_data_processed['Aid'].value_counts())\n",
    "print(route_data_processed['Boulder'].value_counts())\n",
    "print(route_data_processed['Snow'].value_counts())\n",
    "print(route_data_processed['Ice'].value_counts())\n",
    "print(route_data_processed['Mixed'].value_counts())\n",
    "\n",
    "corr = route_data_processed_normalized.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This normalizes the climb data\n",
    "\n",
    "Input: CSV of processed climb data\n",
    "\n",
    "Output: CSV of normalized, processed climb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data_processed = pd.read_csv('route_data_processed.csv', index_col='Id')\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "route_data_processed_normalized = route_data_processed\n",
    "columns_to_normalize = route_data_processed_normalized.columns.drop(['Name', 'Description','Star Rating'])\n",
    "route_data_processed_normalized[columns_to_normalize] = normalizer.fit_transform(route_data_processed_normalized[columns_to_normalize])\n",
    "\n",
    "route_data_processed_normalized.to_csv('route_data_processed_normalized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs linear and ridge regression to predict the overall star rating of a route\n",
    "\n",
    "Input: CSV of normalized, processed climb data\n",
    "\n",
    "Output: Prediction performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_data_processed_normalized = pd.read_csv('route_data_processed_normalized.csv', index_col='Id')\n",
    "route_data_features = route_data_processed_normalized.drop(['Name','Description','Star Rating'], axis=1)\n",
    "route_data_rating = route_data_processed_normalized['Star Rating']\n",
    "route_data_features_train,route_data_features_test,route_data_rating_train,route_data_rating_test = train_test_split(route_data_features, route_data_rating, test_size=0.2, random_state=np.random.RandomState(123))\n",
    "\n",
    "print(route_data_features.columns)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(route_data_features_train,route_data_rating_train)\n",
    "\n",
    "print(\"Linear Bias is \" + str(lr.intercept_))\n",
    "print(\"Linear Coefficients are \" + str(lr.coef_))\n",
    "\n",
    "lr_route_data_rating_test_pred = lr.predict(route_data_features_test)\n",
    "\n",
    "print('Linear MAE: ' + str(mean_absolute_error(route_data_rating_test, lr_route_data_rating_test_pred)))\n",
    "print('Linear MSE: ' + str(mean_squared_error(route_data_rating_test, lr_route_data_rating_test_pred)))\n",
    "print('Linear RMSE: ' + str(mean_squared_error(route_data_rating_test, lr_route_data_rating_test_pred, squared=False)))\n",
    "\n",
    "print('')\n",
    "rr = Ridge()\n",
    "\n",
    "rr.fit(route_data_features_train,route_data_rating_train)\n",
    "\n",
    "print(\"Ridge Bias is \" + str(rr.intercept_))\n",
    "print(\"Ridge Coefficients are \" + str(rr.coef_))\n",
    "\n",
    "rr_route_data_rating_test_pred = rr.predict(route_data_features_test)\n",
    "\n",
    "print('Ridge MAE: ' + str(mean_absolute_error(route_data_rating_test, rr_route_data_rating_test_pred)))\n",
    "print('Ridge MSE: ' + str(mean_squared_error(route_data_rating_test, rr_route_data_rating_test_pred)))\n",
    "print('Ridge RMSE: ' + str(mean_squared_error(route_data_rating_test, rr_route_data_rating_test_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This collects the climb ratings of routes from the Mountain Project website\n",
    "\n",
    "Input: List of valid climb ids\n",
    "\n",
    "Output: CSV of climb ratings by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "\n",
    "if number_of_climbs_for_recommendation_system < len(valid_climbs):\n",
    "    valid_climbs = valid_climbs[:number_of_climbs_for_recommendation_system]\n",
    "\n",
    "climb_ratings = pd.DataFrame(index=valid_climbs)\n",
    "for climb_id in valid_climbs:\n",
    "    URL = 'https://www.mountainproject.com/route/stats/' + str(climb_id) + '/'\n",
    "    page = s.get(URL)\n",
    "    main = BeautifulSoup(page.content, 'html.parser').find('body', id='body-climb').find('div', class_='main-content-container').find('div', class_='container-fluid').find('div', id='route-stats').find_all('div', class_='row')[1].find('div')\n",
    "    if 'Star' in main.find('h3').text:\n",
    "        rating = main.table.find_all('tr')\n",
    "        for row in rating:\n",
    "            columns = row.find_all('td')\n",
    "            user = re.split('/',columns[0].find('a').get('href'))[4]\n",
    "            stars = columns[1].find('span', class_=\"scoreStars\").find_all('img')\n",
    "            rating = 0\n",
    "            if 'bombBlue' not in stars[0]['src']:\n",
    "                rating = len(stars)\n",
    "            climb_ratings.loc[climb_id, user] = rating\n",
    "climb_ratings.to_csv('climb_ratings.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates an item-based recommendation system for the climb data\n",
    "\n",
    "Input: CSV of climb ratings by user\n",
    "\n",
    "Output: Performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climb_ratings = pd.read_csv('climb_ratings.csv', index_col='Id')\n",
    "\n",
    "climb_ratings_train, climb_ratings_test = random_train_test_split(coo_matrix(climb_ratings.to_numpy()), test_percentage=0.2, random_state=np.random.RandomState(123))\n",
    "\n",
    "climb_ratings_train = pd.DataFrame.sparse.from_spmatrix(climb_ratings_train, index=climb_ratings.index, columns=climb_ratings.columns).sparse.to_dense()\n",
    "climb_ratings_test = pd.DataFrame.sparse.from_spmatrix(climb_ratings_test, index=climb_ratings.index, columns=climb_ratings.columns).sparse.to_dense()\n",
    "\n",
    "#Temp Fix\n",
    "climb_ratings_train = climb_ratings_train.replace(0, np.nan)\n",
    "climb_ratings_test = climb_ratings_test.replace(0, np.nan)\n",
    "\n",
    "#adds averages and replaces nans with row average\n",
    "climb_ratings_train['avg'] = climb_ratings_train.mean(axis=1)\n",
    "climb_ratings_train = climb_ratings_train.dropna(how='all').T.fillna(climb_ratings_train['avg'], axis=0).T.astype('int')\n",
    "\n",
    "correlation = 1-pairwise_distances(climb_ratings_train, metric=\"cosine\")\n",
    "\n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(correlation)\n",
    "\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "climb_neighbors = pd.DataFrame(np.append(neighbors_ind, neighbors_distance, axis=1), columns=['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10'], index=climb_ratings_train.index)\n",
    "\n",
    "climb_predictions = []\n",
    "climb_actual = []\n",
    "climb_success = 0\n",
    "climb_unable_to_estimate = 0\n",
    "\n",
    "for climb_id, row in climb_ratings_test.iterrows():\n",
    "    for user, rating in row.iteritems():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(1,11):\n",
    "                if sum(climb_neighbors.index == climb_id) == 0:\n",
    "                    break\n",
    "                ngbh_id = int(climb_neighbors.loc[climb_id, 'N'+str(x)])\n",
    "                nghb_rating = climb_ratings_train.iloc[ngbh_id].loc[user]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = climb_neighbors.loc[climb_id, 'D'+str(x)]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating-climb_ratings_train.iloc[ngbh_id].loc['avg'])\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predicted_rating += climb_ratings_train.loc[climb_id, 'avg']\n",
    "                climb_predictions.append(predicted_rating)\n",
    "                climb_actual.append(rating)\n",
    "                climb_success += 1\n",
    "            else:\n",
    "                climb_unable_to_estimate += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a user-based recommendation system for the climb data\n",
    "\n",
    "Input: CSV of climb ratings by user\n",
    "\n",
    "Output: Performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = pd.read_csv('climb_ratings.csv', index_col='Id').T\n",
    "\n",
    "user_ratings_train, user_ratings_test = random_train_test_split(coo_matrix(user_ratings.to_numpy()), test_percentage=0.2, random_state=np.random.RandomState(123))\n",
    "\n",
    "user_ratings_train = pd.DataFrame.sparse.from_spmatrix(user_ratings_train, index=user_ratings.index, columns=user_ratings.columns).sparse.to_dense()\n",
    "user_ratings_test = pd.DataFrame.sparse.from_spmatrix(user_ratings_test, index=user_ratings.index, columns=user_ratings.columns).sparse.to_dense()\n",
    "\n",
    "#Temp Fix\n",
    "user_ratings_train = user_ratings_train.replace(0, np.nan)\n",
    "user_ratings_test = user_ratings_test.replace(0, np.nan)\n",
    "\n",
    "#adds averages and replaces nans with row average\n",
    "user_ratings_train['avg'] = user_ratings_train.mean(axis=1)\n",
    "user_ratings_train = user_ratings_train.dropna(how='all').T.fillna(user_ratings_train['avg'], axis=0).T.astype('int')\n",
    "\n",
    "correlation = 1-pairwise_distances(user_ratings_train, metric=\"cosine\")\n",
    "\n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(correlation)\n",
    "\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "user_neighbors = pd.DataFrame(np.append(neighbors_ind, neighbors_distance, axis=1), columns=['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10'], index=user_ratings_train.index)\n",
    "\n",
    "user_predictions = []\n",
    "user_actual = []\n",
    "user_success = 0\n",
    "user_unable_to_estimate = 0\n",
    "\n",
    "for user_id, row in user_ratings_test.iterrows():\n",
    "    for climb, rating in row.iteritems():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(1,11):\n",
    "                if sum(user_neighbors.index == user_id) == 0:\n",
    "                    break\n",
    "                ngbh_id = int(user_neighbors.loc[user_id, 'N'+str(x)])\n",
    "                nghb_rating = user_ratings_train.iloc[ngbh_id].loc[climb]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = user_neighbors.loc[user_id, 'D'+str(x)]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating-user_ratings_train.iloc[ngbh_id].loc['avg'])\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predicted_rating += user_ratings_train.loc[user_id, 'avg']\n",
    "                user_predictions.append(predicted_rating)\n",
    "                user_actual.append(rating)\n",
    "                user_success += 1\n",
    "            else:\n",
    "                user_unable_to_estimate += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analyzes the performance of the recommendation systems\n",
    "\n",
    "Input: Performance data\n",
    "\n",
    "Output: Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Climb MAE: ' + str(mean_absolute_error(climb_actual, climb_predictions)))\n",
    "print('Climb MSE: ' + str(mean_squared_error(climb_actual, climb_predictions)))\n",
    "print('Climb RMSE: ' + str(mean_squared_error(climb_actual, climb_predictions, squared=False)))\n",
    "print('Climb Number Could Estimate: ' + str(climb_success))\n",
    "print('Climb Number Could Not Estimate: ' + str(climb_unable_to_estimate))\n",
    "climb_over_estimate = np.array(climb_predictions)-np.array(climb_actual)\n",
    "plt.hist(climb_over_estimate, bins=4)\n",
    "plt.xlabel('Deviation from Actual')\n",
    "plt.title('Item Based Recommendation Performance')\n",
    "plt.savefig('item_based_recommendation_performance.png')\n",
    "plt.clf()\n",
    "\n",
    "print('User MAE: ' + str(mean_absolute_error(user_actual, user_predictions)))\n",
    "print('User MSE: ' + str(mean_squared_error(user_actual, user_predictions)))\n",
    "print('User RMSE: ' + str(mean_squared_error(user_actual, user_predictions, squared=False)))\n",
    "print('User Number Could Estimate: ' + str(user_success))\n",
    "print('User Number Could Not Estimate: ' + str(user_unable_to_estimate))\n",
    "user_over_estimate = np.array(user_predictions)-np.array(user_actual)\n",
    "plt.hist(user_over_estimate, bins=4)\n",
    "plt.xlabel('Deviation from Actual')\n",
    "plt.title('User Based Recommendation Performance')\n",
    "plt.savefig('user_based_recommendation_performance.png')\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
